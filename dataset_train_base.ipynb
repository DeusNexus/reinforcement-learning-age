{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b504d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_ID: b01f6c\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "# Sci-kit Learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple, Optional, Callable, Dict, List\n",
    "\n",
    "# Unique run UUID\n",
    "import uuid\n",
    "RUN_ID = str(uuid.uuid4()).replace('-', '')[:6]\n",
    "print(f\"RUN_ID: {RUN_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ca6ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata DataFrames:\n",
      "df_md_train shape: (4065, 5)\n",
      "df_md_valid shape: (1482, 5)\n",
      "df_md_test shape: (1978, 5)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imageId",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2f3e1393-5aba-4fb0-be26-7cad9b172b8b",
       "rows": [
        [
         "0",
         "1",
         "5.0",
         "male",
         "caucasian",
         "neutral"
        ],
        [
         "1",
         "2",
         "20.0793650793651",
         "female",
         "caucasian",
         "neutral"
        ],
        [
         "2",
         "3",
         "76.8157894736842",
         "female",
         "caucasian",
         "slightlyhappy"
        ],
        [
         "3",
         "4",
         "55.6578947368421",
         "female",
         "caucasian",
         "happy"
        ],
        [
         "4",
         "5",
         "17.6666666666667",
         "female",
         "caucasian",
         "slightlyhappy"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.079365</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>76.815789</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>slightlyhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>55.657895</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>slightlyhappy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imageId        age  gender  ethnicity        emotion\n",
       "0        1   5.000000    male  caucasian        neutral\n",
       "1        2  20.079365  female  caucasian        neutral\n",
       "2        3  76.815789  female  caucasian  slightlyhappy\n",
       "3        4  55.657895  female  caucasian          happy\n",
       "4        5  17.666667  female  caucasian  slightlyhappy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "# Set folder paths #\n",
    "####################\n",
    "\n",
    "# Root path\n",
    "dataset_root = Path('./datasets/appa-real-dataset_v2')\n",
    "\n",
    "# Labels metadata paths\n",
    "labels_md_train = dataset_root / 'labels_metadata_train.csv'\n",
    "labels_md_valid = dataset_root / 'labels_metadata_valid.csv'\n",
    "labels_md_test = dataset_root / 'labels_metadata_test.csv'\n",
    "\n",
    "# Dataset paths\n",
    "ds_train = dataset_root / 'train_data'\n",
    "ds_valid = dataset_root / 'valid_data'\n",
    "ds_test = dataset_root / 'test_data'\n",
    "\n",
    "# Create dataframe for metadata: train, valid, test\n",
    "df_md_train = pd.read_csv(labels_md_train)\n",
    "df_md_valid = pd.read_csv(labels_md_valid)\n",
    "df_md_test = pd.read_csv(labels_md_test)\n",
    "\n",
    "# Inspect\n",
    "print(\"Metadata DataFrames:\")\n",
    "print(f\"df_md_train shape: {df_md_train.shape}\")\n",
    "print(f\"df_md_valid shape: {df_md_valid.shape}\")\n",
    "print(f\"df_md_test shape: {df_md_test.shape}\\n\")\n",
    "\n",
    "# Just the metadata dataframe, no images yet.\n",
    "df_md_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8506c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Bin Frequencies: {'[0, 1)': 1, '[1, 2)': 85, '[2, 3)': 33, '[3, 4)': 32, '[4, 5)': 53, '[5, 6)': 45, '[6, 7)': 39, '[7, 8)': 28, '[8, 9)': 29, '[9, 10)': 19, '[10, 11)': 13, '[11, 12)': 17, '[12, 13)': 13, '[13, 14)': 12, '[14, 15)': 28, '[15, 16)': 35, '[16, 17)': 65, '[17, 18)': 70, '[18, 19)': 68, '[19, 20)': 111, '[20, 21)': 132, '[21, 22)': 126, '[22, 23)': 156, '[23, 24)': 157, '[24, 25)': 181, '[25, 26)': 174, '[26, 27)': 161, '[27, 28)': 139, '[28, 29)': 145, '[29, 30)': 134, '[30, 31)': 126, '[31, 32)': 110, '[32, 33)': 95, '[33, 34)': 97, '[34, 35)': 74, '[35, 36)': 90, '[36, 37)': 75, '[37, 38)': 98, '[38, 39)': 61, '[39, 40)': 58, '[40, 41)': 53, '[41, 42)': 60, '[42, 43)': 46, '[43, 44)': 33, '[44, 45)': 44, '[45, 46)': 36, '[46, 47)': 46, '[47, 48)': 33, '[48, 49)': 33, '[49, 50)': 25, '[50, 51)': 37, '[51, 52)': 39, '[52, 53)': 48, '[53, 54)': 35, '[54, 55)': 30, '[55, 56)': 36, '[56, 57)': 26, '[57, 58)': 27, '[58, 59)': 18, '[59, 60)': 27, '[60, 61)': 20, '[61, 62)': 11, '[62, 63)': 13, '[63, 64)': 10, '[64, 65)': 10, '[65, 66)': 10, '[66, 67)': 8, '[67, 68)': 9, '[68, 69)': 12, '[69, 70)': 4, '[70, 71)': 1, '[71, 72)': 6, '[72, 73)': 5, '[73, 74)': 5, '[74, 75)': 2, '[75, 76)': 3, '[76, 77)': 4, '[77, 78)': 0, '[78, 79)': 0, '[79, 80)': 5, '[80, 81)': 3, '[81, 82)': 0, '[82, 83)': 2, '[83, 84)': 2, '[84, 85)': 0, '[85, 86)': 1, '[86, 87)': 1, '[87, 88)': 0, '[88, 89)': 0, '[89, 90)': 1}\n",
      "Age Oversampling Weights: {'[0, 1)': 20.0, '[1, 2)': np.float64(2.1294117647058823), '[2, 3)': np.float64(5.484848484848484), '[3, 4)': np.float64(5.65625), '[4, 5)': np.float64(3.4150943396226414), '[5, 6)': np.float64(4.022222222222222), '[6, 7)': np.float64(4.641025641025641), '[7, 8)': np.float64(6.464285714285714), '[8, 9)': np.float64(6.241379310344827), '[9, 10)': np.float64(9.526315789473685), '[10, 11)': np.float64(13.923076923076923), '[11, 12)': np.float64(10.647058823529411), '[12, 13)': np.float64(13.923076923076923), '[13, 14)': np.float64(15.083333333333334), '[14, 15)': np.float64(6.464285714285714), '[15, 16)': np.float64(5.171428571428572), '[16, 17)': np.float64(2.7846153846153845), '[17, 18)': np.float64(2.585714285714286), '[18, 19)': np.float64(2.661764705882353), '[19, 20)': np.float64(1.6306306306306306), '[20, 21)': np.float64(1.371212121212121), '[21, 22)': np.float64(1.4365079365079365), '[22, 23)': np.float64(1.1602564102564104), '[23, 24)': np.float64(1.1528662420382165), '[24, 25)': np.float64(1.0), '[25, 26)': np.float64(1.0402298850574712), '[26, 27)': np.float64(1.124223602484472), '[27, 28)': np.float64(1.3021582733812949), '[28, 29)': np.float64(1.2482758620689656), '[29, 30)': np.float64(1.3507462686567164), '[30, 31)': np.float64(1.4365079365079365), '[31, 32)': np.float64(1.6454545454545455), '[32, 33)': np.float64(1.9052631578947368), '[33, 34)': np.float64(1.865979381443299), '[34, 35)': np.float64(2.445945945945946), '[35, 36)': np.float64(2.011111111111111), '[36, 37)': np.float64(2.4133333333333336), '[37, 38)': np.float64(1.846938775510204), '[38, 39)': np.float64(2.9672131147540983), '[39, 40)': np.float64(3.1206896551724137), '[40, 41)': np.float64(3.4150943396226414), '[41, 42)': np.float64(3.0166666666666666), '[42, 43)': np.float64(3.9347826086956523), '[43, 44)': np.float64(5.484848484848484), '[44, 45)': np.float64(4.113636363636363), '[45, 46)': np.float64(5.027777777777778), '[46, 47)': np.float64(3.9347826086956523), '[47, 48)': np.float64(5.484848484848484), '[48, 49)': np.float64(5.484848484848484), '[49, 50)': np.float64(7.24), '[50, 51)': np.float64(4.891891891891892), '[51, 52)': np.float64(4.641025641025641), '[52, 53)': np.float64(3.7708333333333335), '[53, 54)': np.float64(5.171428571428572), '[54, 55)': np.float64(6.033333333333333), '[55, 56)': np.float64(5.027777777777778), '[56, 57)': np.float64(6.961538461538462), '[57, 58)': np.float64(6.703703703703703), '[58, 59)': np.float64(10.055555555555555), '[59, 60)': np.float64(6.703703703703703), '[60, 61)': np.float64(9.05), '[61, 62)': np.float64(16.454545454545453), '[62, 63)': np.float64(13.923076923076923), '[63, 64)': np.float64(18.1), '[64, 65)': np.float64(18.1), '[65, 66)': np.float64(18.1), '[66, 67)': 20.0, '[67, 68)': 20.0, '[68, 69)': np.float64(15.083333333333334), '[69, 70)': 20.0, '[70, 71)': 20.0, '[71, 72)': 20.0, '[72, 73)': 20.0, '[73, 74)': 20.0, '[74, 75)': 20.0, '[75, 76)': 20.0, '[76, 77)': 20.0, '[79, 80)': 20.0, '[80, 81)': 20.0, '[82, 83)': 20.0, '[83, 84)': 20.0, '[85, 86)': 20.0, '[86, 87)': 20.0, '[89, 90)': 20.0}\n",
      "Sample Weights Example: [np.float64(2.391834541495506), np.float64(1.3506310108919592), np.float64(4.030668175766495), np.float64(2.64991399502222), np.float64(1.9849376914289714), np.float64(3.4792659581385412), np.float64(1.1520285684938671), np.float64(2.138054020719406), np.float64(3.2341435001055565), np.float64(1.733623263148065), np.float64(1.9789893260897191), np.float64(4.819040303623539), np.float64(2.73692537201185), np.float64(1.7907816769880136), np.float64(2.5698712873486835), np.float64(1.3971510265268523), np.float64(1.0), np.float64(2.5698712873486835), np.float64(2.2631410199262083), np.float64(1.9849376914289714)]\n"
     ]
    }
   ],
   "source": [
    "def compute_sample_weights(\n",
    "    df_train: pd.DataFrame,\n",
    "    max_oversample_multiplier: float = 20.0,\n",
    "    apply_log_smoothing: bool = False,\n",
    "    balance_gender: bool = False,\n",
    "    balance_ethnicity: bool = False\n",
    ") -> Tuple[pd.DataFrame, Dict[str, int], Dict[str, float], List[float], WeightedRandomSampler]:\n",
    "    \"\"\"\n",
    "    Compute per-sample weights based on age bins, and optionally gender and ethnicity balancing.\n",
    "    Returns updated dataframe, frequency dicts, sample weights, and a WeightedRandomSampler.\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame): DataFrame containing 'age', 'gender', 'ethnicity'.\n",
    "        max_oversample_multiplier (float): Maximum cap for oversampling multiplier.\n",
    "        apply_log_smoothing (bool): Apply log smoothing to weights.\n",
    "        balance_gender (bool): Whether to include gender balancing.\n",
    "        balance_ethnicity (bool): Whether to include ethnicity balancing.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "            - Updated DataFrame with 'age_binned' column.\n",
    "            - Age bin frequencies dictionary.\n",
    "            - Oversampling weights dictionary.\n",
    "            - Per-sample weights list.\n",
    "            - WeightedRandomSampler instance for DataLoader.\n",
    "    \"\"\"\n",
    "    df_train = df_train.copy()\n",
    "\n",
    "    # ----- Age Binning -----\n",
    "    bins = range(int(df_train['age'].min()), int(df_train['age'].max()) + 2)\n",
    "    df_train['age_binned'] = pd.cut(df_train['age'], bins=bins, right=False)\n",
    "\n",
    "    age_counts = df_train['age_binned'].value_counts().sort_index()\n",
    "    age_bin_dict = {str(interval): int(count) for interval, count in zip(age_counts.index, age_counts.values)}\n",
    "\n",
    "    # Compute inverse frequencies for age bins\n",
    "    max_age_count = max(age_counts.values)\n",
    "    age_weights = {\n",
    "        str(interval): min((max_age_count / count), max_oversample_multiplier)\n",
    "        for interval, count in zip(age_counts.index, age_counts.values)\n",
    "        if count > 0\n",
    "    }\n",
    "\n",
    "    # ----- Gender Balancing -----\n",
    "    if balance_gender:\n",
    "        gender_counts = df_train['gender'].value_counts()\n",
    "        max_gender_count = max(gender_counts.values)\n",
    "        gender_weights = {\n",
    "            gender: min((max_gender_count / count), max_oversample_multiplier)\n",
    "            for gender, count in gender_counts.items()\n",
    "        }\n",
    "    else:\n",
    "        gender_weights = {gender: 1.0 for gender in df_train['gender'].unique()}\n",
    "\n",
    "    # ----- Ethnicity Balancing -----\n",
    "    if balance_ethnicity:\n",
    "        ethnicity_counts = df_train['ethnicity'].value_counts()\n",
    "        max_ethnicity_count = max(ethnicity_counts.values)\n",
    "        ethnicity_weights = {\n",
    "            ethnicity: min((max_ethnicity_count / count), max_oversample_multiplier)\n",
    "            for ethnicity, count in ethnicity_counts.items()\n",
    "        }\n",
    "    else:\n",
    "        ethnicity_weights = {ethnicity: 1.0 for ethnicity in df_train['ethnicity'].unique()}\n",
    "\n",
    "    # ----- Compute Final Sample Weights -----\n",
    "    sample_weights: List[float] = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        age_weight = age_weights[str(row['age_binned'])]\n",
    "        gender_weight = gender_weights[row['gender']]\n",
    "        ethnicity_weight = ethnicity_weights[row['ethnicity']]\n",
    "\n",
    "        combined_weight = age_weight * gender_weight * ethnicity_weight\n",
    "\n",
    "        if apply_log_smoothing:\n",
    "            combined_weight = 1 + np.log1p(combined_weight - 1)\n",
    "\n",
    "        sample_weights.append(min(combined_weight, max_oversample_multiplier))\n",
    "\n",
    "    # ----- Weighted Sampler -----\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.DoubleTensor(sample_weights),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    return df_train, age_bin_dict, age_weights, sample_weights, sampler\n",
    "\n",
    "\n",
    "df_train_binned, age_bin_dict, age_weights, sample_weights, train_sampler = compute_sample_weights(\n",
    "    df_md_train,  # Calculate the weights from the metadata descriptions\n",
    "    max_oversample_multiplier=20.0,\n",
    "    apply_log_smoothing=True,\n",
    "    balance_gender=True,\n",
    "    balance_ethnicity=True\n",
    ")\n",
    "\n",
    "print(\"Age Bin Frequencies:\", age_bin_dict)\n",
    "print(\"Age Oversampling Weights:\", age_weights)\n",
    "print(\"Sample Weights Example:\", sample_weights[:20])  # First 20 samples\n",
    "\n",
    "# Optional if you want gender/ethnicity weights explicitly:\n",
    "#print(\"Gender Weights:\", gender_weights)\n",
    "#print(\"Ethnicity Weights:\", ethnicity_weights)\n",
    "\n",
    "\n",
    "# # DataLoader with sampler\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=16,\n",
    "#     sampler=train_sampler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06099d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Labels: {0: 'female', 1: 'male'}\n",
      "Ethnicity Labels: {0: 'afroamerican', 1: 'asian', 2: 'caucasian'}\n",
      "Emotion Labels: {0: 'happy', 1: 'neutral', 2: 'other', 3: 'slightlyhappy'}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate encoders\n",
    "gender_encoder = LabelEncoder()\n",
    "ethnicity_encoder = LabelEncoder()\n",
    "emotion_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on TRAIN ONLY\n",
    "gender_encoder.fit(df_md_train['gender'])\n",
    "ethnicity_encoder.fit(df_md_train['ethnicity'])\n",
    "emotion_encoder.fit(df_md_train['emotion'])\n",
    "\n",
    "# Transform on train, valid, and test\n",
    "df_md_train['gender_encoded'] = gender_encoder.transform(df_md_train['gender'])\n",
    "df_md_valid['gender_encoded'] = gender_encoder.transform(df_md_valid['gender'])\n",
    "df_md_test['gender_encoded']  = gender_encoder.transform(df_md_test['gender'])\n",
    "\n",
    "df_md_train['ethnicity_encoded'] = ethnicity_encoder.transform(df_md_train['ethnicity'])\n",
    "df_md_valid['ethnicity_encoded'] = ethnicity_encoder.transform(df_md_valid['ethnicity'])\n",
    "df_md_test['ethnicity_encoded']  = ethnicity_encoder.transform(df_md_test['ethnicity'])\n",
    "\n",
    "df_md_train['emotion_encoded'] = emotion_encoder.transform(df_md_train['emotion'])\n",
    "df_md_valid['emotion_encoded'] = emotion_encoder.transform(df_md_valid['emotion'])\n",
    "df_md_test['emotion_encoded']  = emotion_encoder.transform(df_md_test['emotion'])\n",
    "\n",
    "# Debug info: mappings\n",
    "print(\"Gender Labels:\", dict(enumerate(gender_encoder.classes_)))\n",
    "print(\"Ethnicity Labels:\", dict(enumerate(ethnicity_encoder.classes_)))\n",
    "print(\"Emotion Labels:\", dict(enumerate(emotion_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ee03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute min/max from train data\n",
    "age_min = df_md_train['age'].min()\n",
    "age_max = df_md_train['age'].max()\n",
    "\n",
    "# Normalize using train's min/max\n",
    "df_md_train['age_normalized'] = (df_md_train['age'] - age_min) / (age_max - age_min)\n",
    "df_md_valid['age_normalized'] = (df_md_valid['age'] - age_min) / (age_max - age_min)\n",
    "df_md_test['age_normalized']  = (df_md_test['age']  - age_min) / (age_max - age_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09140f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imageId",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emotion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ethnicity_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "emotion_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age_normalized",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4c57c679-17fe-4153-84b2-7db414da3d64",
       "rows": [
        [
         "0",
         "1",
         "5.0",
         "male",
         "caucasian",
         "neutral",
         "1",
         "2",
         "1",
         "0.04620749782040102"
        ],
        [
         "1",
         "2",
         "20.0793650793651",
         "female",
         "caucasian",
         "neutral",
         "0",
         "2",
         "1",
         "0.2171157332447656"
        ],
        [
         "2",
         "3",
         "76.8157894736842",
         "female",
         "caucasian",
         "slightlyhappy",
         "0",
         "2",
         "3",
         "0.860161519754049"
        ],
        [
         "3",
         "4",
         "55.6578947368421",
         "female",
         "caucasian",
         "happy",
         "0",
         "2",
         "0",
         "0.6203597485431098"
        ],
        [
         "4",
         "5",
         "17.6666666666667",
         "female",
         "caucasian",
         "slightlyhappy",
         "0",
         "2",
         "3",
         "0.18977041557686744"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>ethnicity_encoded</th>\n",
       "      <th>emotion_encoded</th>\n",
       "      <th>age_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.079365</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>76.815789</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>slightlyhappy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.860162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>55.657895</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>slightlyhappy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.189770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imageId        age  gender  ethnicity        emotion  gender_encoded  \\\n",
       "0        1   5.000000    male  caucasian        neutral               1   \n",
       "1        2  20.079365  female  caucasian        neutral               0   \n",
       "2        3  76.815789  female  caucasian  slightlyhappy               0   \n",
       "3        4  55.657895  female  caucasian          happy               0   \n",
       "4        5  17.666667  female  caucasian  slightlyhappy               0   \n",
       "\n",
       "   ethnicity_encoded  emotion_encoded  age_normalized  \n",
       "0                  2                1        0.046207  \n",
       "1                  2                1        0.217116  \n",
       "2                  2                3        0.860162  \n",
       "3                  2                0        0.620360  \n",
       "4                  2                3        0.189770  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_md_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7867236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imageId",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emotion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ethnicity_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "emotion_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age_normalized",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a40f9d7c-c859-4fd1-82a7-c59987226210",
       "rows": [
        [
         "0",
         "1",
         "26.2307692307692",
         "male",
         "afroamerican",
         "happy",
         "1",
         "0",
         "0",
         "0.2868352223190928"
        ],
        [
         "1",
         "2",
         "27.2564102564103",
         "male",
         "caucasian",
         "other",
         "1",
         "2",
         "2",
         "0.29845975007265363"
        ],
        [
         "2",
         "3",
         "23.1428571428571",
         "male",
         "caucasian",
         "slightlyhappy",
         "1",
         "2",
         "3",
         "0.25183709054676734"
        ],
        [
         "3",
         "4",
         "73.2894736842105",
         "female",
         "caucasian",
         "happy",
         "0",
         "2",
         "0",
         "0.820194557885559"
        ],
        [
         "4",
         "5",
         "20.1428571428571",
         "female",
         "caucasian",
         "happy",
         "0",
         "2",
         "0",
         "0.2178353468676043"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>ethnicity_encoded</th>\n",
       "      <th>emotion_encoded</th>\n",
       "      <th>age_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26.230769</td>\n",
       "      <td>male</td>\n",
       "      <td>afroamerican</td>\n",
       "      <td>happy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27.256410</td>\n",
       "      <td>male</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.298460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>male</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>slightlyhappy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.251837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>73.289474</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.142857</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imageId        age  gender     ethnicity        emotion  gender_encoded  \\\n",
       "0        1  26.230769    male  afroamerican          happy               1   \n",
       "1        2  27.256410    male     caucasian          other               1   \n",
       "2        3  23.142857    male     caucasian  slightlyhappy               1   \n",
       "3        4  73.289474  female     caucasian          happy               0   \n",
       "4        5  20.142857  female     caucasian          happy               0   \n",
       "\n",
       "   ethnicity_encoded  emotion_encoded  age_normalized  \n",
       "0                  0                0        0.286835  \n",
       "1                  2                2        0.298460  \n",
       "2                  2                3        0.251837  \n",
       "3                  2                0        0.820195  \n",
       "4                  2                0        0.217835  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_md_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b81b799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imageId",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emotion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ethnicity_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "emotion_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age_normalized",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c9024909-f07e-4fa5-816d-9251cc5d3853",
       "rows": [
        [
         "0",
         "1",
         "23.2051282051282",
         "female",
         "caucasian",
         "neutral",
         "0",
         "2",
         "1",
         "0.25254286544609106"
        ],
        [
         "1",
         "2",
         "70.7368421052632",
         "male",
         "asian",
         "slightlyhappy",
         "1",
         "1",
         "3",
         "0.7912632496673243"
        ],
        [
         "2",
         "3",
         "55.3684210526316",
         "male",
         "asian",
         "happy",
         "1",
         "1",
         "0",
         "0.6170788785389802"
        ],
        [
         "3",
         "4",
         "24.2777777777778",
         "male",
         "caucasian",
         "neutral",
         "1",
         "2",
         "1",
         "0.2647001840550229"
        ],
        [
         "4",
         "5",
         "25.2307692307692",
         "female",
         "caucasian",
         "neutral",
         "0",
         "2",
         "1",
         "0.27550130775937176"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>ethnicity_encoded</th>\n",
       "      <th>emotion_encoded</th>\n",
       "      <th>age_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23.205128</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>70.736842</td>\n",
       "      <td>male</td>\n",
       "      <td>asian</td>\n",
       "      <td>slightlyhappy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.791263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>55.368421</td>\n",
       "      <td>male</td>\n",
       "      <td>asian</td>\n",
       "      <td>happy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24.277778</td>\n",
       "      <td>male</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25.230769</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imageId        age  gender  ethnicity        emotion  gender_encoded  \\\n",
       "0        1  23.205128  female  caucasian        neutral               0   \n",
       "1        2  70.736842    male      asian  slightlyhappy               1   \n",
       "2        3  55.368421    male      asian          happy               1   \n",
       "3        4  24.277778    male  caucasian        neutral               1   \n",
       "4        5  25.230769  female  caucasian        neutral               0   \n",
       "\n",
       "   ethnicity_encoded  emotion_encoded  age_normalized  \n",
       "0                  2                1        0.252543  \n",
       "1                  1                3        0.791263  \n",
       "2                  1                0        0.617079  \n",
       "3                  2                1        0.264700  \n",
       "4                  2                1        0.275501  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_md_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be378951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWithMetadataDataset(Dataset):\n",
    "    def __init__(self, df_md: pd.DataFrame, images_dir: Path, transform=None, age_min=None, age_max=None):\n",
    "        self.df = df_md\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.age_min = age_min\n",
    "        self.age_max = age_max\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = f\"{int(row['imageId']):06d}.jpg\"\n",
    "        img_path = self.images_dir / img_name\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Labels\n",
    "        gender = row['gender_encoded']\n",
    "        ethnicity = row['ethnicity_encoded']\n",
    "        emotion = row['emotion_encoded']\n",
    "        \n",
    "        # Normalize age if parameters are set\n",
    "        if self.age_min is not None and self.age_max is not None:\n",
    "            age = (row['age'] - self.age_min) / (self.age_max - self.age_min)\n",
    "        else:\n",
    "            age = row['age']\n",
    "\n",
    "        return image, torch.tensor([age], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c857184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the images are preprocessed accordingly\n",
    "train_transform: Callable = transforms.Compose([\n",
    "    transforms.ToTensor(),  # ✅ Converts to Tensor with shape (C, H, W), scaled to [0,1]\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize from [0,1] → [-1,1]\n",
    "])\n",
    "\n",
    "# During evaluation DONT use data augmentation!\n",
    "val_transform: Callable = transforms.Compose([\n",
    "    transforms.ToTensor(),  # ✅ Converts to Tensor with shape (C, H, W), scaled to [0,1]\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = ImageWithMetadataDataset(df_md_train, ds_train, transform=train_transform, age_min=age_min, age_max=age_max)\n",
    "valid_dataset = ImageWithMetadataDataset(df_md_valid, ds_valid, transform=val_transform, age_min=age_min, age_max=age_max)\n",
    "test_dataset  = ImageWithMetadataDataset(df_md_test,  ds_test,  transform=val_transform, age_min=age_min, age_max=age_max)\n",
    "\n",
    "# Set batch size for saving\n",
    "load_batch_size = 48\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=load_batch_size, sampler=train_sampler)  # No shuffle because sampler handles it\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=load_batch_size)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=load_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8f1105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts_config_b01f6c.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "artifacts = {\n",
    "    'run_id':RUN_ID,\n",
    "    'age_min': float(age_min),\n",
    "    'age_max': float(age_max),\n",
    "    'gender_classes': gender_encoder.classes_.tolist(),\n",
    "    'ethnicity_classes': ethnicity_encoder.classes_.tolist(),\n",
    "    'emotion_classes': emotion_encoder.classes_.tolist(),\n",
    "    'train_transform_config': {\n",
    "        'resize': (224, 224),\n",
    "        'normalize_mean': [0.5, 0.5, 0.5],\n",
    "        'normalize_std': [0.5, 0.5, 0.5],\n",
    "        'augmentation': {\n",
    "            'random_horizontal_flip': 0.5,\n",
    "            'color_jitter': {\n",
    "                'brightness': 0.2,\n",
    "                'contrast': 0.2,\n",
    "                'saturation': 0.2,\n",
    "                'hue': 0.1\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'load_batch_size': load_batch_size\n",
    "}\n",
    "\n",
    "with open(f'artifacts_config_{RUN_ID}.json', 'w') as f:\n",
    "    json.dump(artifacts, f, indent=4)\n",
    "\n",
    "print(f\"Saved artifacts_config_{RUN_ID}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39a8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/google/vit-base-patch16-224-in21k\n",
    "\n",
    "class ViTRegressionModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='google/vit-base-patch16-224-in21k'):\n",
    "        super(ViTRegressionModel, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained(pretrained_model_name)\n",
    "        self.regressor = nn.Linear(self.vit.config.hidden_size, 1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        outputs = self.vit(x)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        age_pred = self.regressor(pooled_output)\n",
    "        return age_pred\n",
    "    \n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, ages in loader:\n",
    "            images = images.to(device)\n",
    "            ages = ages.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ages)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "def log_training_history(epoch: int, train_loss: float, val_loss: float, log_file: str = f'training_history_{RUN_ID}.json'):\n",
    "    \"\"\"\n",
    "    Appends training history (epoch, train_loss, val_loss) to a JSON file.\n",
    "    If the file doesn't exist, it will create it.\n",
    "    \"\"\"\n",
    "    log_path = Path(log_file)\n",
    "\n",
    "    # If file exists, load current history\n",
    "    if log_path.exists():\n",
    "        with open(log_path, 'r') as f:\n",
    "            history = json.load(f)\n",
    "    else:\n",
    "        history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    # Append new epoch data\n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    # Save back to file\n",
    "    with open(log_path, 'w') as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    print(f\"Appended Epoch {epoch} to {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59652c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  14%|█▍        | 12/85 [00:06<00:34,  2.09it/s]"
     ]
    }
   ],
   "source": [
    "# First freeze ViT backbone to initialize weights for regression head, potentially stablizing training and accuracy.\n",
    "# Next, whole model will be trained to propagate fine-tuning throughout all layers.\n",
    "\n",
    "# Using Mixed Precision for Lower Memory Footprint and higher speed.\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Device Setup\n",
    "device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize Model and Move to Device\n",
    "model: ViTRegressionModel = ViTRegressionModel()\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze ViT backbone: Only train the regression head initially\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion: _Loss = nn.MSELoss()\n",
    "optimizer: Optimizer = optim.AdamW(model.regressor.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop (head-only) - 5 epochs\n",
    "dtype_to_use = torch.bfloat16  # <- USE bfloat16 instead of float16\n",
    "best_val_loss = float('inf') # Initialize to infinity\n",
    "epochs: int = 5\n",
    "scaler = GradScaler() # For AMP\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss: float = 0.0\n",
    "\n",
    "    for images, ages in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        # Move data to device\n",
    "        images, ages = images.to(device), ages.to(device)\n",
    "\n",
    "        optimizer.zero_grad()             # Reset gradients for this step\n",
    "        with autocast(device_type='cuda', dtype=dtype_to_use):\n",
    "            outputs: torch.Tensor = model(images)          # Forward pass\n",
    "            loss: torch.Tensor = criterion(outputs, ages)  # Compute loss\n",
    "        \n",
    "        scaler.scale(loss).backward()                      # Backpropagation\n",
    "        scaler.step(optimizer)                             # Optimizer step\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()     # Accumulate loss for reporting\n",
    "\n",
    "    # Print epoch-level loss\n",
    "    avg_loss: float = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation loss is computed\n",
    "    val_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Save checkpoint only if validation loss improved\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'age_min': age_min,\n",
    "            'age_max': age_max,\n",
    "            'gender_encoder_classes': gender_encoder.classes_.tolist(),\n",
    "            'ethnicity_encoder_classes': ethnicity_encoder.classes_.tolist(),\n",
    "            'emotion_encoder_classes': emotion_encoder.classes_.tolist()\n",
    "        }, f'best_vit_regressor_partial_checkpoint_{RUN_ID}.pth')\n",
    "        print(f\"Saved BEST checkpoint at epoch {epoch+1} with val_loss: {val_loss:.6f}\")\n",
    "    \n",
    "    # Save train history every epoch\n",
    "    log_training_history(epoch + 1, avg_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58937a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Mixed Precision for Lower Memory Footprint and higher speed.\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Unfreeze ViT backbone for fine-tuning\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Re-initialize optimizer to update ALL model parameters now\n",
    "optimizer: Optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Loss function remains the same\n",
    "criterion: _Loss = nn.MSELoss()\n",
    "\n",
    "# Training loop (full fine-tuning)\n",
    "dtype_to_use = torch.bfloat16  # <- USE bfloat16 instead of float16\n",
    "epochs: int = 15\n",
    "best_val_loss = float('inf') # Initialize to infinity\n",
    "scaler = GradScaler() # For AMP\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss: float = 0.0\n",
    "\n",
    "    for images, ages in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images = images.to(device)\n",
    "        ages = ages.to(device)\n",
    "\n",
    "        optimizer.zero_grad()             # Reset gradients for this step\n",
    "        with autocast(device_type='cuda', dtype=dtype_to_use):\n",
    "            outputs: torch.Tensor = model(images)          # Forward pass\n",
    "            loss: torch.Tensor = criterion(outputs, ages)  # Compute loss\n",
    "        \n",
    "        scaler.scale(loss).backward()                      # Backpropagation\n",
    "        scaler.step(optimizer)                             # Optimizer step\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()       # Accumulate batch loss\n",
    "\n",
    "    # Print epoch-level loss\n",
    "    avg_loss: float = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation loss is computed\n",
    "    val_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Save checkpoint only if validation loss improved\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'age_min': age_min,\n",
    "            'age_max': age_max,\n",
    "            'gender_encoder_classes': gender_encoder.classes_.tolist(),\n",
    "            'ethnicity_encoder_classes': ethnicity_encoder.classes_.tolist(),\n",
    "            'emotion_encoder_classes': emotion_encoder.classes_.tolist()\n",
    "        }, f'best_vit_regressor_full_checkpoint_{RUN_ID}.pth')\n",
    "        print(f\"Saved BEST checkpoint at epoch {epoch+1} with val_loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Save train history every epoch\n",
    "    log_training_history(epoch + 1, avg_loss, val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3008611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Test Evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate(model, loader, device, age_min, age_max):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for images, ages in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.cpu().numpy().flatten()\n",
    "            targets = ages.numpy().flatten()\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(targets)\n",
    "    \n",
    "    # Denormalize predictions and targets back to actual ages\n",
    "    all_preds = np.array(all_preds) * (age_max - age_min) + age_min\n",
    "    all_targets = np.array(all_targets) * (age_max - age_min) + age_min\n",
    "\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    return mse, mae\n",
    "\n",
    "# Run evaluation with denormalization\n",
    "mse, mae = evaluate(model, test_loader, device, age_min, age_max)\n",
    "print(f\"Test MSE: {mse:.6f}, MAE: {mae:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
